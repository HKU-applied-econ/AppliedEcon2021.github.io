\RequirePackage{currfile}
\tolerance=5000
\documentclass[10pt, xcolor=x11names,compress,usenames,dvipsnames]{beamer}

\usepackage[english]{babel}

\usepackage[framemethod=TikZ]{mdframed}

\usepackage{amssymb,amsmath,amsfonts,eurosym,geometry,ulem,graphicx,caption,color,setspace,comment,footmisc,caption,pdflscape,subfigure,array,hyperref,upgreek,bbm,xcolor,float,amsthm,amsmath,verbatim,setspace,ulem,textpos,changepage,url,multirow,tikz,color, colortbl,numprint,mathrsfs,cancel,wrapfig,booktabs,threeparttable,ebgaramond,natbib}

\usetikzlibrary{fit,shapes.geometric}

\newcounter{nodemarkers}
\newcommand\circletext[1]{%
	\tikz[overlay,remember picture]
	\node (marker-\arabic{nodemarkers}-a) at (0,1.5ex) {};%
	#1%
	\tikz[overlay,remember picture]
	\node (marker-\arabic{nodemarkers}-b) at (0,0){};%
	\tikz[overlay,remember picture,inner sep=2pt]
	\node[draw,rectangle,red ,fit=(marker-\arabic{nodemarkers}-a.center) (marker-\arabic{nodemarkers}-b.center)] {};%
	\stepcounter{nodemarkers}%
}


\setbeamertemplate{footline}[frame number]


\normalem

\newcommand{\tsout}[1]{\text{\sout{$#1$}}}
\definecolor{Gray}{gray}{0.9}
\newcolumntype{g}{>{\columncolor{Gray}}c}

\newtheorem{remark}{Remark}
\def\mb{\mathbf}
\def\iid{\mathrm{i.i.d.}}
\def\bs{\boldsymbol}
\def\tbf{\textbf}
\def\t{^{\top}}
\def\E{\mathbbm{E}}
\def\bSig{\bs{\Sigma}}

\newcommand{\mcitet}[1]{\mbox{\citet{#1}}}
\newcommand{\mcitep}[1]{\mbox{\citep{#1}}}
\newcommand{\ind}{\mathbbm{1}}

\DeclareMathOperator{\vect}{vec}
\DeclareMathOperator{\vecth}{vech}



\newcommand{\R}{\mathbbm{R}}
\newcommand{\prob}{\mathbbm{P}}
\newcommand{\var}{\text{var}}

\newtheorem{assumption}{Assumption}

\newtheorem{hyp}{Hypothesis}
\newtheorem{subhyp}{Hypothesis}[hyp]
\renewcommand{\thesubhyp}{\thehyp\alph{subhyp}}

\newcommand{\red}[1]{{\color{red} #1}}
\newcommand{\blue}[1]{{\color{blue} #1}}

\makeatletter
\newenvironment<>{proofs}[1][\proofname]{%
	\par
	\def\insertproofname{#1\@addpunct{.}}%
	\usebeamertemplate{proof begin}#2}
{\usebeamertemplate{proof end}}
\makeatother


\newcolumntype{L}[1]{>{\raggedright\let\newline\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\arraybackslash\hspace{0pt}}m{#1}}
\setbeamertemplate{theorems}[numbered]
% Themes
\mode<presentation> {
	\usetheme{Hannover}
	\usecolortheme{default}
	\setbeamercovered{transparent}
}

\setbeamercovered{transparent}

\setbeamertemplate{itemize item}{$\triangleright$}
\setbeamertemplate{itemize subitem}{$\diamond$}
\setbeamertemplate{enumerate items}[default]
\setbeamerfont{frametitle}{size=\large}
\PassOptionsToPackage{height=1cm}{beamerouterthemesidebar}
\usepackage{blindtext}

% Title
\title[IV]{Instrumental Variables Regression \footnote[frame]{This section is based on \cite{Stock2020}, Chapter 12.}
}
\date[]{\today}


\author[Hao]{Jasmine(Yu) Hao}
\institute[VSE]{Faculty of Business and Economics\\Hong Kong University}


\begin{document}
	
	\begin{frame}
		\maketitle
	\end{frame}

\begin{frame}[allowframebreaks]{Motivation}
\begin{itemize}
\item
  Instrumental variables (IV) regression is a general way to obtain a
  consistent estimator of the unknown causal coefficients when the
  regressor, \(X\), is correlated with the error term, \(u\).
\item
  To understand how IV regression works, think of the variation in \(X\)
  as having two parts: one part that, for whatever reason, is correlated
  with \(u\) (this is the part that causes the problems) and a second
  part that is uncorrelated with \(u\).
\item
  If you had information that allowed you to isolate the second part,
  you could focus on those variations in X that are uncorrelated with
  \(u\) and disregard the variations in X that bias the OLS estimates.
  \pagebreak
\item
  This is, in fact, what IV regression does. The information about the
  movements in \(X\) that are uncorrelated with u is gleaned from one or
  more additional variables, called instrumental variables or simply
  instruments.
\item
  Instrumental variables regression uses these additional variables as
  tools or ``instruments'' to isolate the movements in \(X\) that are
  uncorrelated with u, which in turn permits consistent estimation of
  the regression coefficients.
\end{itemize}
\end{frame}

\section[Single Regressor]{The IV Estimator with a Single Regressor and a Single Instrument}
\begin{frame}{IV Model}
\begin{itemize}
\item
  We start with the case of a single regressor, \(X\), which might be
  correlated with the error, \(u\). \\
  If \(X\) and \(u\) are correlated, the OLS estimator is inconsistent;
  that is, it may not be close to the true value of the causal
  coefficient even when the sample is very large.
\item
  This correlation between \(X\) and \(u\) can stem from various
  sources, including omitted variables, errors in variables (measurement
  errors in the regressors), and simultaneous causality (when causality
  runs ``backward'' from \(Y\) to \(X\) as well as ``forward'' from
  \(X\) to \(Y\)).
\item
  Whatever the source of the correlation between \(X\) and \(u\), if
  there is a valid instrumental variable, \(Z\), the effect on \(Y\) of
  a unit change in \(X\) can be estimated using the instrumental
  variables estimator.
\end{itemize}
\end{frame}

\subsection[Assumptions]{The IV Model and Assumptions}
\begin{frame}{Assumptions}
	
Let \(\beta_1\) be the causal effect of \(X\) on \(Y\). The model
relating the dependent variable \(Y_i\) and regressor Xi, without any
control variables, is

\[Y_i = \beta_0 + \beta_1 X_i + u_i, i = 1,\ldots, n, (12.1)\]

\begin{itemize}
\item
  where \(u_i\) is the error term representing omitted factors that
  determine \(Y_i\).
\item
  If \(X_i\) and \(u_i\) are correlated, the OLS estimator is
  inconsistent. Instrumental variables estimation uses an additional,
  ``instrumental'' variable \(Z\) to isolate that part of \(X\) that is
  uncorrelated with \(u\).
\end{itemize}
\end{frame}

\subsubsection{Endogeneity and Exogeneity}
\begin{frame}[allowframebreaks]{Endogeneity and Exogeneity}
	
\begin{itemize}
\item
  Instrumental variables regression has some specialized terminology to
  distinguish variables that are correlated with the population error
  term \(u\) from ones that are not.
\item
  Variables correlated with the error term are called endogenous
  variables, while variables uncorrelated with the error term are called
  exogenous variables.
\item
  The historical source of these terms traces to models with multiple
  equations, in which an ``endogenous'' variable is determined within
  the model, while an ``exogenous'' variable is determined outside the
  model.
  \pagebreak
\item
  For example, Section 9.2 considered the possibility that if low test
  scores produced decreases in the student--teacher ratio because of
  political intervention and increased funding, causality would run both
  from the student--teacher ratio to test scores and from test scores to
  the student--teacher ratio. This was represented mathematically as a
  system of two simultaneous equations,  one for each causal connection.
\item
  As discussed in Section 9.2, because both test scores and the
  student--teacher ratio are determined within the model, both are
  correlated with the population error term \(u\); that is, in this
  example, both variables are endogenous. In contrast, an exogenous
  variable, which is determined outside the model, is uncorrelated with
  \(u\).
\end{itemize}
\end{frame}

\subsubsection[Valid Instrument]{The two conditions for a valid instrument}
\begin{frame}[allowframebreaks]{The two conditions for a valid instrument}
A valid instrumental variable (``instrument'') \(Z\) must satisfy two
conditions, known as the instrument relevance condition and the
instrument exogeneity condition:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Instrument relevance: \(corr(Z_i, X_i) \neq 0\).
\item
  Instrument exogeneity: \(corr(Z_i, u_i) = 0\).
\end{enumerate}
\pagebreak
If an instrument is relevant, then variation in the instrument is
related to variation in \(X_i\). If in addition the instrument is
exogenous, then that part of the variation of \(X_i\) captured by the
instrumental variable is exogenous. \\
Thus an instrument that is relevant and exogenous can capture movements
in Xi that are exogenous. \\
This exogenous variation can in turn be used to estimate the population
coefficient \(\beta_1\).\\
The two conditions for a valid instrument are vital for instrumental
variables regression, and we return to them (and their extension to
multiple regressors and multiple instruments) repeatedly throughout this
chapter.
\end{frame}

\subsection[2SLS]{The Two Stage Least Squares Estimator}
\begin{frame}[allowframebreaks]{The Two Stage Least Squares Estimator}

\begin{itemize}
\item
  If the instrument \(Z\) satisfies the conditions of instrument
  relevance and exogeneity, the coefficient \(\beta_1\) can be estimated
  using an IV estimator called two stage least squares (TSLS).
\item
  As the name suggests, the two stage least squares estimator is
  calculated in two stages. The first stage decomposes \(X\) into two
  components: a problematic component that may be correlated with the
  regression error and another, problem-free component that is
  uncorrelated with the error. The second stage uses the problem-free
  component to estimate \(\beta_1\).
\end{itemize}

The first stage begins with a population regression linking \(X\) and
\(Z\):

\[X_i = \pi_0 + \pi_1 Z_i + v_i,\]

\begin{itemize}
\item
  where \(\pi_0\) is the intercept, \(\pi_1\) is the slope, and \(v_i\)
  is the error term.
\item
  This regression provides the needed decomposition of \(X_i\). One
  component is \(\pi_0 + \pi_1 Z_i\), the part of \(X_i\) that can be
  predicted by \(Z_i\). \\
  Because \(Z_i\) is exogenous, this component of \(X_i\) is
  uncorrelated with \(u_i\), the error term in Equation (12.1). The
  other component of \(X_i\) is \(v_i\), which is the problematic
  component of Xi that is correlated with \(u_i\).
\item
  The idea behind TSLS is to use the problem-free component of \(X_i\),
  \(\pi_0 + \pi_1 Z_i\), and to disregard \(v_i\).
\item
  The only complication is that the values of \(\pi_0\) and \(\pi_1\)
  are unknown, so \(\pi_0 + \pi_1 Z_i\) cannot be calculated. \\
  Accordingly, the first stage of TSLS applies OLS to Equation (12.2)
  and uses the predicted value from the OLS
  regression,\(\hat X_i = \hat\pi_0 + \hat\pi_1 Z_i\), where
  \(\hat \pi_0\) and \(\hat \pi_1\) are OLS estimators.
\item
  The second stage of TSLS is easy: Regress \(Y_i\) on \(\hat X_i\)
  using OLS. \\
  The resulting estimators from the second-stage regression are the TSLS
  estimators, \(\hat \beta_0^{TSLS}\) and \(\hat \beta_1^{TSLS}\).
\end{itemize}
\end{frame}

\subsection{Why does IV regression work?}
\subsubsection[Example 1]{Example 1: Philip Wright's problem}
\begin{frame}[allowframebreaks]{Example 1: Philip Wright's problem}

\begin{itemize}
\item
  The method of instrumental variables estimation was first published in
  1928 in an appendix to a book written by Philip G. Wright(1928),
  although the key ideas of IV regression were developed collaboratively
  with his son Sewall Wright (see the box ``When Was Instrumental
  Variables Regression Invented?'').
\item
  Philip Wright was concerned with an important economic problem of his
  day: \textbf{how to set an import tariff (a tax on imported goods) on
  animal and vegetable oils and fats, such as butter and soy oil. In the
  1920s, import tariffs were a major source of tax revenue for the
  United States}. The key to understanding the economic effect of a
  tariff was having quantitative estimates of the demand and supply
  curves of the goods. Recall that the supply elasticity is the
  percentage change in the quantity supplied arising from a 1\% increase
  in the price and that the demand elasticity is the percentage change
  in the quantity demanded arising from a 1\% increase in the price.
\item
  Philip Wright needed estimates of these elasticities of supply and
  demand. To be concrete, consider the problem of estimating the
  elasticity of demand for butter. Recall from Key Concept 8.2 that the
  coefficient in a linear equation relating \(\ln(Y_i)\) to \(\ln(X_i)\)
  has the interpretation of the elasticity of Y with respect to \(X\).
  \\
  In Wright's problem, this suggests the demand equation
\end{itemize}

\[\ln(Q^{butter}_i) = \beta_0 + \beta_1 \ln(P^{Butter}_i) + u_i, (12.3)\]

\begin{itemize}
\item
  where \(Q^{butter}_i\) is the i-th observation on the quantity of
  butter consumed, \(P^{butter}_i\) is its price, and \(u_i\) represents
  other factors that affect demand, such as income and consumer
  tastes.\\
  In Equation (12.3), a 1\% increase in the price of butter yields a
  \(\beta_1\) percent change in demand, so \(\beta_1\) is the demand
  elasticity.
\item
  Philip Wright had data on total annual butter consumption and its
  average annual price in the United States for 1912 to 1922. It would
  have been easy to use these data to estimate the demand elasticity by
  applying OLS to Equation (12.3), but he had a key insight: Because of
  the interactions between supply and demand, the regressor,
  \(\ln(P^{Butter}_i)\) was likely to be correlated with the error term.
\end{itemize}
\end{frame}

\begin{figure}
\centering
\includegraphics[width=0.7\linewidth]{../figure/W4_9.png}
\end{figure}

\begin{frame}[allowframebreaks]{Example 1}
\begin{itemize}
\item
  To see this, look at Figure 12.1a, which shows the market demand and
  supply curves for butter for three different years. The demand and
  supply curves for the first period are denoted $D_1$ and $S_1$, and the
  first period's equilibrium price and quantity are determined by their
  intersection.
\item
  In year 2, demand increases from $D_1$ to $D_2$ (say, because of an increase in income), and supply decreases from $S_1$ to $S_2$ (because of an increase in the cost of producing butter); the equilibrium price and quantity are determined by the intersection of the new supply and demand curves. In year 3, the factors affecting demand and supply change
  again; demand increases again to $D_3$, supply increases to $S_3$, and a new equilibrium quantity and price are determined.
\item
  Figure 12.1b shows the equilibrium quantity and price pairs for these
  three periods and for eight subsequent years, where in each year the
  supply and demand curves are subject to shifts associated with factors
  other than price that affect market supply and demand. This
  scatterplot is like the one that Wright would have seen when he
  plotted his data. As he reasoned, fitting a line to these points by
  OLS will estimate neither a demand curve nor a supply curve because
  the points have been determined by changes in both demand and supply.
\item
  Wright realized that a way to get around this problem was to find some
  third variable that shifted supply but did not shift demand. Figure
  12.1c shows what happens when such a variable shifts the supply curve
  but demand remains stable. Now all of the equilibrium price and
  quantity pairs lie on a stable demand curve, and the slope of the
  demand curve is easily estimated. In the instrumental variable
  formulation of Wright's problem, this third variable---the
  instrumental variable---is correlated with price (it shifts the supply
  curve, which leads to a change in price) but is uncorrelated with
  \(u\) (the demand curve remains stable). Wright considered several
  potential instrumental variables; one was the weather. For example,
  below-average rainfall in a dairy region could impair grazing and thus
  reduce butter production at a given price (it would shift the supply
  curve to the left and increase the equilibrium price), so dairy-region
  rainfall satisfies the condition for instrument relevance.
\item
  But dairy-region rainfall should not have a direct influence on the
  demand for butter, so the correlation between dairy-region rainfall
  and \(u_i\) would be \(0\); that is, dairy-region rainfall satisfies
  the condition for instrument exogeneity.
\end{itemize}
\end{frame}


\subsubsection[Example 2]{Example 2: Estimating the effect on test scores of class size}
\begin{frame}[allowframebreaks]{Example 2: Estimating the effect on test scores of class size}
\begin{itemize}
\item
  Despite controlling for student and district characteristics, the
  estimates of the effect on test scores of class size reported in Part
  II still might have omitted variable bias resulting from unmeasured
  variables such as learning opportunities outside school or the quality
  of the teachers.
\item
  If data on these variables, or on suitable control variables, are
  unavailable, this omitted variable bias cannot be addressed by
  including the variables in the multiple regressions. Instrumental
  variables regression provides an alternative approach to this problem.
  Consider the following hypothetical example: Some California schools
  are forced to close for repairs because of a summer earthquake.
\item
  Districts closest to the epicenter are most severely affected. A
  district with some closed schools needs to ``double up'' its students,
  temporarily increasing class size. This means that distance from the
  epicenter satisfies the condition for instrument relevance because it
  is correlated with class size. But if distance to the epicenter is
  unrelated to any of the other factors affecting student performance
  (such as whether the students are still learning English or disruptive
  effects of the earthquake on student performance), then it will be
  exogenous because it is uncorrelated with the error term. Thus the
  instrumental variable, distance to the epicenter, could be used to
  circumvent omitted variable bias and to estimate the effect of class
  size on test scores.
\end{itemize}
\end{frame}


\begin{frame}{The Sampling Distribution of the TSLS Estimator}
  
\begin{itemize}
\item
  The exact distribution of the TSLS estimator in small samples is
  complicated.\\
  However, like the OLS estimator, its distribution in large samples is
  simple: The TSLS estimator is consistent and is normally distributed.
\end{itemize}
\end{frame}

\subsubsection{Formula for the TSLS estimator}
\begin{frame}[allowframebreaks]{Formula for the TSLS estimator}
  
\begin{itemize}
\item
  Although the two stages of TSLS make the estimator seem complicated,
  when there is a single X and a single instrument \(Z\), as we assume
  in this section, there is a simple formula for the TSLS estimator. Let
  \(s_{ZY}\) be the sample covariance between \(Z\) and \(Y\), and let
  \(s_{ZX}\) be the sample covariance between \(Z\) and \(X\).
\item
  As shown in Appendix 12.2, the TSLS estimator with a single instrument
  is
\end{itemize}

\[\hat \beta^{TSLS} = \frac{s_{ZY}}{s_{ZX}},(12.4)\]

\begin{itemize}
\item
  That is, the TSLS estimator of \(\beta_1\) is the ratio of the sample
  covariance between \(Z\) and \(Y\) to the sample covariance between
  \(Z\) and \(X\).
\end{itemize}
\end{frame}

\subsubsection[Asymptotic]{Sampling distribution of bnTSLS1 when the sample size is large}
\begin{frame}[allowframebreaks]{Sampling distribution of bnTSLS1 when the sample size is large}
  
\begin{itemize}
\item
  The formula in Equation(12.4) can be used to show that bnTSLS1 is
  consistent and, in large samples, normally distributed.
\item
  The argument that bnTSLS 1 is consistent combines the assumptions that
  \(Z_i\) is relevant and exogenous with the consistency of sample
  covariances for population covariances. To begin, note that because
  \(Y_i = \beta_0 + \beta_1 X_i + u_i\) in Equation (12.1),
  \(s_{ZY} \to_p cov(Z,Y)\) and \(s_{ZX} \to_p cov(Z,X)\).\\
  It follows from Equations (12.4) and (12.6) that the TSLS estimator is
  consistent:
\end{itemize}

\[\hat \beta_1 = \frac{s_{ZY}}{s_{ZX}} \to_p \frac{cov(Z_i,Y_i)}{cov(Z_i,X_i)} = \beta_1.\]

\begin{itemize}
\item
  The formula in Equation (12.4) also can be used to show that the
  sampling distribution of \(\hat\beta^{TSLS}\) is normal in large
  samples.
\item
  The reason is the same as for every other least squares estimator we
  have considered: The TSLS estimator is an average of random variables,
  and when the sample size is large, the central limit theorem tells us
  that averages of random variables are normally distributed.
\item
  Specifically, the numerator of the expression for
  \(\hat\beta_1^{TSLS}\) an average of
  \(s_{ZY} = \frac{1}{n-1}(Z_i - \bar Z)(Y_i - \bar Y)\).
\item
  A bit of algebra, sketched out in Appendix 12.3, shows that because of
  this averaging, the central limit theorem implies that, in large\\
  samples, \(\hat\beta_1^{TSLS}\) has a sampling distribution that is
  approximately \(N(\beta_1,\sigma^2_{\hat\beta_1^{TSLS}})\), where
\end{itemize}

\[\sigma^2_{\hat\beta_1^{TSLS}} = \frac{1}{n} \frac{var[(Z_i - \mu_Z) u_i]}{ [cov(Z_i,X_i)]^2}.\]

\end{frame}


\subsubsection[Inference]{Statistical inference using the large-sample distribution}
\begin{frame}{Statistical inference using the large-sample distribution}

  \begin{itemize}
    \item The variance \(\sigma^2_{\hat\beta_1^{TSLS}}\) can be estimated by estimating the variance and covariance terms appearing, and the square root of the estimate of \(\sigma^2_{\hat\beta_1^{TSLS}}\) is the standard error of the IV estimator. 
    \item This is done automatically in TSLS regression commands in econometric software packages. \\
    \item Because \(\hat\beta_1^{TSLS}\) is normally distributed in large samples, hypothesis tests about \(\beta_1\) can be performed by computing the t-statistic, and a 95\% large-sample  confidence interval is given by \(\hat\beta_1^{TSLS} \pm 1.96 \sigma_{\hat\beta_1^{TSLS}}\).

  \end{itemize}

\end{frame}

\subsection[Application]{Application to the Demand for Cigarettes}
\begin{frame}[allowframebreaks]{Application to the Demand for Cigarettes}

\begin{itemize}
\item
  Philip Wright was interested in the demand elasticity of butter, but
  Wright's thinking could be explored with a view to estimating other
  important quantities. One example is the spending elasticity for
  mortality, the percentage change in avoidable mortality resulting from
  a 1\% increase in healthcare expenditure, where researchers have also
  used an IV estimator to overcome simultaneous equation bias to inform
  health policy debates. Other examples concern other commodities,
  besides butter, such as cigarettes, which today figure more
  prominently in public policy debates.
\item
  The answer to this question depends on the elasticity of demand for
  cigarettes. If the elasticity is -1, then the 20\% target in
  consumption can be achieved by a 20\% increase in price. If the
  elasticity is -0.5, then the price must rise 40\% to decrease
  consumption by 20\%. Of course, we do not know the demand elasticity
  of cigarettes: We must estimate it from data on prices and sales. But,
  as with butter, because of the interactions between supply and demand,
  the elasticity of demand for cigarettes cannot be estimated
  consistently by an OLS regression of log quantity on log price.
\item
  We therefore use TSLS to estimate the elasticity of demand for
  cigarettes using annual data for the 48 contiguous U.S. states for
  1985 through 1995 (the data are described in Appendix 12.1). For now,
  all the results are for the cross section of states in 1995; results
  using data for earlier years (panel data) are presented in Section
  12.4.\\
  The instrumental variable, \(SalesTax_i\), is the portion of the tax
  on cigarettes arising from the general sales tax, measured in dollars
  per pack (in real dollars, deflated by the Consumer Price Index).
  Cigarette consumption, \(Q^{cigarettes}_i\), is the number of packs of
  cigarettes sold per capita in the state, and the price,
  \(P^{cigarettes}_i\), is the average real price per pack of cigarettes
  including all taxes.
\item
  Before using TSLS, it is essential to ask whether the two conditions
  for instrument validity hold. We return to this topic in detail in
  Section 12.3, where we provide some statistical tools that help in
  this assessment. Even with those statistical tools, judgment plays an
  important role, so it is useful to think about whether the sales tax
  on cigarettes plausibly satisfies the two conditions.

  \begin{itemize}
  \item
    First consider instrument relevance. Because a high sales tax
    increases the aftertax sales price \(P^{cigarettes}_i\), the sales
    tax per pack plausibly satisfies the condition for instrument
    relevance.
  \item
    Next consider instrument exogeneity. For the sales tax to be
    exogenous, it must be uncorrelated with the error in the demand
    equation; that is, the sales tax must affect the demand for
    cigarettes only indirectly through the price. This seems plausible:
    General sales tax rates vary from state to state, but they do so
    mainly because different states choose different mixes of sales,
    income, property, and other taxes to finance public undertakings.
    Those choices about public finance are driven by political
    considerations, not by factors related to the demand for cigarettes.
    We discuss the credibility of this assumption more in Section 12.4,
    but for now we keep it as a working hypothesis.
  \end{itemize}
\end{itemize}

In modern statistical software, the first stage of TSLS is estimated
automatically, so you do not need to run this regression yourself to
compute the TSLS estimator. Even so, it is a good idea to look at the
first-stage regression. Using data for the 48 states in 1995, it is,

\[\ln(P^{cigarettes}_i) = \underset{(0.03)}{4.62} + \underset{(0.005)}{0.031} SalesTax_i.(12.9)\]

\begin{itemize}
\item
  As expected, higher sales taxes mean higher after-tax prices. The
  \(R^2\) of this regression is 47\%, so the variation in sales tax on
  cigarettes explains 47\% of the variance of cigarette prices across
  states.
\item
  In the second stage of \(TSLS\), \(\ln(Q^{cigarettes}_i)\) is
  regressed on \(\ln(P^{cigarettes}_i)\) using OLS. The resulting
  estimated regression function is
\end{itemize}

\[\widehat{\ln(Q^{cigarettes}_i)} = 9.72 - 1.08 \widehat{\ln(P^{cigarettes}_i)}.\]

\begin{itemize}
\item
  This estimated regression function is written using the regressor in
  the second stage, the predicted value
  \(\widehat{\ln(P^{cigarettes}_i)}\).
\item
  It is, however, conventional and less cumbersome simply to report the
  estimated regression function with \(\ln(P^{cigarettes}_i)\) rather
  than \(\widehat{\ln(P^{cigarettes}_i)}\). \\
  Reported in this notation, the TSLS estimates and
  heteroskedasticityrobust standard errors are
\end{itemize}

\[\widehat{\ln(Q^{cigarettes}_i)} = \underset{(1.53)}{9.72} - \underset{(0.32)}{1.08} \widehat{\ln(P^{cigarettes}_i)}.\]

\begin{itemize}
\item
  The TSLS estimate suggests that the demand for cigarettes is
  surprisingly elastic in light of their addictive nature: An increase
  in the price of 1\% reduces consumption by 1.08\%. But, recalling our
  discussion of instrument exogeneity, perhaps this estimate should not
  yet be taken too seriously. Even though the elasticity was estimated
  using an instrumental variable, there might still be omitted variables
  that are correlated with the sales tax per pack.
\item
  A leading candidate is income: States with higher incomes might depend
  relatively less on a sales tax and more on an income tax to finance
  state government. Moreover, the demand for cigarettes presumably
  depends on income. Thus we would like to reestimate our demand
  equation including income as a control variable. To do so, however, we
  must first extend the IV regression model to include additional
  regressors.
\end{itemize}
\end{frame}

\section[General Model]{The General IV Regression Model}

\begin{frame}[allowframebreaks]{The General IV Regression Model}
  
The general IV regression model has four types of variables:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  the dependent variable, \(Y\);
\item
  problematic endogenous regressors, like the price of cigarettes, which
  are correlated with the error term and which we will label \(X\);
\item
  additional regressors \(W\), which are either control variables or
  included exogenous variables;
\item
  and instrumental variables, \(Z\).
\end{enumerate}

\begin{itemize}
\item
  In general, there can be multiple endogenous regressors (\(X\)'s),
  multiple additional regressors (W's), and multiple instrumental
  variables (\(Z\)'s).
\item
  For IV regression to be possible, there must be at least as many
  instrumental variables (\(Z\)'s) as endogenous regressors (\(X\)'s).
  In Section 12.1, there was a single endogenous regressor and a single
  instrument.
\item
  Having (at least) one instrument for this single endogenous regressor
  was essential. Without the instrument, we could not have computed the
  instrumental variables estimator: there would be no first-stage
  regression in TSLS.
\end{itemize}

The relationship between the number of instruments and the number of
endogenous regressors has its own terminology.

\begin{itemize}
\item
  The regression coefficients are said to be \textbf{exactly identified}
  if the number of instruments \((m)\) equals the number of endogenous
  regressors \((k)\); that is, \(m = k\).
\item
  The coefficients are overidentified if the number of instruments
  exceeds the number of endogenous regressors; that is, \(m > k\).
\item
  They are underidentified if the number of instruments is less than the
  number of endogenous regressors; that is, \(m < k\). The coefficients
  must be either exactly identified or overidentified if they are to be
  estimated by IV regression.
\end{itemize}
\end{frame}

\subsubsection[Exogenous Variable]{Included exogenous variables and control variables in IV regression}
\begin{frame}[allowframebreaks]{Included exogenous variables and control variables in IV regression}
\begin{itemize}
\item
  The \(W\) variables in Equation (12.12) can be either exogenous
  variables, in which case \(E[u_i|W_i]=0\), or they can be control
  variables that need not have a causal interpretation but are included
  to ensure that the instrument is uncorrelated with the error term.
\item
  For example, Section 12.1 raised the possibility that the sales tax
  might be correlated with income, which economic theory tells us is a
  determinant of cigarette demand. If so, the sales tax would be
  correlated with the error term in the cigarette demand equation, \\
  \(\ln(Q_i^{cigarettes}) = \beta_0 + \beta_1 \ln(P_i^{cigarettes}) + u_i\),
  and thus would not be an exogenous instrument. Including income in the
  IV regression, or including variables that control for income, would
  remove this source of potential correlation between the instrument and
  the error term.
\item
  In general, if \(W\) is an effective control variable in IV
  regression, then including \(W\) makes the instrument uncorrelated
  with \(u\), so the TSLS estimator of the coefficient on \(X\) is
  consistent; if \(W\) is correlated with u, however, then the TSLS
  coefficient on \(W\) is subject to omitted\\
  variable bias and does not have a causal interpretation.
\item
  The mathematical condition for W to be an effective control variable
  in IV regression is similar to the condition on control variables in
  OLS discussed in Section 7.5.
\item
  Specifically, including \(W\) must ensure that the conditional mean of
  \(u\) does not depend on \(Z\), so conditional mean independence
  holds; that is, \(E[u_i|Z_i,W_i] = E[u_i|W_i]\).
\item
  For clarity, in the body of this chapter we focus on the case that
  \(W\) variables are exogenous, so that \(E[u_i |W_i] = 0\). \\
  Appendix 12.6 explains how the results of this chapter extend to the
  case that \(W\) is a control variable, in which case the conditional
  mean \(0\) condition, \(E[u_i|W_i]=0\), is replaced by the conditional
  mean independence condition, \(E[u_i|Z_i,W_i] = E[u_i|W_i]\).
\end{itemize}
\end{frame}

\subsection{TSLS in the General IV Model}

\begin{figure}
\centering
\includegraphics[width=\linewidth]{../figure/W4_10.png}
\end{figure}

\subsubsection{TSLS with a single endogenous regressor}
\begin{frame}[allowframebreaks]{TSLS with a single endogenous regressor}
  
\begin{itemize}
\item
  When there is a single endogenous regressor \(X\) and some additional
  included exogenous variables, the equation of interest is
\end{itemize}

\[Y_i = \beta_0 + \beta_1 X_i + \beta_2 W_{1i} + \ldots + \beta_{1+r} W_{ri} + u_i, (12.13)\]

\begin{itemize}
\item
  where, as before, \(X_i\) might be correlated with the error term, but
  \(W_{1i},\ldots, W_{ri}\) are not.
\item
  The population first-stage regression of TSLS relates \(X\) to the
  exogenous variables---that is, the \(W\)'s and the instruments
  (\(Z\)'s):
\end{itemize}

\[X_i = \pi_0 + \pi_1 Z_{1i} + \ldots + \pi_m Z_{mi} + \pi_{m+1} W_{1i} + \ldots + \pi_{m+r} W_{ri} + v_i, (12.14)\]

\begin{itemize}
\item
  where \(\pi_0, \pi_1,\ldots, \pi_{m+r}\) are unknown regression
  coefficients and vi is an error term. Equation (12.14) is sometimes
  called the reduced form equation for \(X\).
\item
  It relates the endogenous variable \(X\) to all the available
  exogenous variables, both those included in the regression of interest
  \((W)\) and the instruments \((Z)\).
\item
  In the first stage of TSLS, the unknown coefficients in Equation
  (12.14) are estimated by OLS, and the predicted values from this
  regression are \(\hat X_{1},\ldots, \hat X_{n}\).
\item
  In the second stage of TSLS, Equation (12.13) is estimated by OLS
  except that \(X_i\) is replaced by its predicted value from the first
  stage. That is, \(Y_i\) is regressed on
  \(\hat X_i, W_{1i}, \ldots, W_{ri}\) using OLS. \\
  The resulting estimator of \(\beta_0,\beta_1,\ldots,\beta_{1+r}\) is
  the TSLS estimator.
\end{itemize}
\end{frame}

\subsection[Validity]{Instrument Relevance and Exogeneity in the General IV Model}
\begin{frame}[allowframebreaks]{Instrument Relevance and Exogeneity in the General IV Model}
  
\begin{itemize}
\item
  The conditions of instrument relevance and exogeneity need to be
  modified for the general IV regression model.
\item
  When there is one included endogenous variable but multiple
  instruments, the condition for instrument relevance is that at least
  one \(Z\) is useful for predicting \(X\) given \(W\).
\item
  When there are multiple included endogenous variables, this condition
  is more complicated because we must rule out perfect multicollinearity
  in the secondstage population regression. Intuitively, when there are
  multiple included endogenous variables, the instruments must provide
  enough information about the exogenous movements in these variables to
  sort out their separate effects on \(Y\).
\end{itemize}
\end{frame}

\subsection[Inference]{The IV Regression Assumptions and Sampling Distribution of the TSLS Estimator}


\subsubsection[Assumptions]{The IV regression assumptions}
\begin{frame}[allowframebreaks]{The IV regression assumptions}
  
\begin{itemize}
\item
  The IV regression assumptions are modifications of the least squares
  assumptions for causal inference in the multiple regression model in
  Key Concept 6.4.

  \begin{itemize}
  \item
    The first IV regression assumption modifies the conditional mean
    assumption in Key Concept 6.4 to apply only to the included
    exogenous variables.
  \item
    The second IV regression assumption is that the draws are i.i.d., as
    they are if the data are collected by simple random sampling.
  \item
    The third IV assumption is that large outliers are unlikely.
  \item
    The fourth IV regression assumption is that the two conditions for
    instrument validity in Key Concept 12.3 hold. The instrument
    relevance condition in Key Concept 12.3 subsumes the fourth least
    squares assumption in Key Concepts 6.4 and 6.6 (no perfect
    multicollinearity) by assuming that the regressors in the
    second-stage regression are not perfectly multicollinear.
  \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Sampling distribution of the TSLS estimator}

\begin{itemize}
\item
  Under the IV regression assumptions, the TSLS estimator is consistent
  and normally distributed in large samples.
\item
  Conceptually, the reasoning in Section 12.1 carries over to the
  general case of multiple instruments and multiple included endogenous
  variables.
\item
  The expressions in the general case are complicated(SW Chapter 19 for
  reference).
\end{itemize}
\end{frame}

\begin{frame}{Inference Using the TSLS Estimator}
Because the sampling distribution of the TSLS estimator is normal in
large samples, the general procedures for statistical inference
(hypothesis tests and confidence intervals) in regression models extend
to TSLS regression. For example, 95\% confidence intervals are
constructed as the TSLS estimator \(\pm\) 1.96 standard errors.
Similarly, joint hypotheses about the population values of the
coefficients can be tested using the F-statistic.
\end{frame}

\begin{frame}[allowframebreaks]{Calculation of TSLS standard errors}
There are two points to bear in mind about TSLS standard errors.

\begin{itemize}
\item
  First, the standard errors reported by OLS estimation of the
  second-stage regression are incorrect because they do not recognize
  that it is the second stage of a two-stage process.
\item
  Specifically, the second-stage OLS standard errors fail to adjust for
  the second-stage regression using the predicted values of the included
  endogenous variables. Formulas for standard errors that make the
  necessary adjustment are incorporated into (and automatically used by)
  TSLS regression commands in econometric software.
\end{itemize}

Therefore, this issue is not a concern in practice if you use a
specialized TSLS regression command. Second, as always the error u might
be heteroskedastic. It is therefore important to use
heteroskedasticity-robust versions of the standard errors for precisely
the same reason that it is important to use heteroskedasticity-robust
standard errors for the OLS estimators of the multiple regression model.
\end{frame}

\begin{frame}[allowframebreaks]{Application to the Demand for Cigarettes}
\begin{itemize}
\item
  In Section 12.1, we estimated the elasticity of demand for cigarettes
  using data on annual consumption in 48 U.S. states in 1995 using TSLS
  with a single regressor (the logarithm of the real price per pack) and
  a single instrument (the real sales tax per pack).
\item
  Income also affects demand, however, so it is part of the error term
  of the population regression. As discussed in Section 12.1, if the
  state sales tax is related to state income, it is correlated with a
  variable in the error term of the cigarette demand equation, which
  violates the instrument exogeneity condition.
\item
  If so, the IV estimator in Section 12.1 is inconsistent. That is, the
  IV regression suffers from a version of omitted variable bias. We can
  solve this problem by including income in the regression.
\end{itemize}

We therefore consider an alternative specification in which the
logarithm of income is included in the demand equation.

\begin{itemize}
\item
  the dependent variable \(Y\) is the logarithm of consumption,
  \(\ln(Q^{cigarettes}_i)\);
\item
  the endogenous regressor \(X\) is the logarithm of the real after-tax
  price, \(\ln(P^{cigarettes}_i)\);
\item
  the included exogenous variable W is the logarithm of the real per
  capita state income, \(\ln(Inc_i)\);
\item
  and the instrument \(Z\) is the real sales tax per pack,
  \(SalesTax_i\). The TSLS estimates and (heteroskedasticity-robust)
  standard errors are
\end{itemize}

\[\widehat{\ln(Q^{cigarettes}_i)} = \underset{(1.26)}{9.43} - \underset{(0.37)}{1.14} \ln(P^{cigarettes}) + \underset{(0.31)}{0.21} \ln(Inc_i).\]

\begin{itemize}
\item
  This regression uses a single instrument, \(SalesTax_i\), but, in
  fact, another candidate instrument is available. In addition to
  general sales taxes, states levy special taxes that apply only to
  cigarettes and other tobacco products.
\item
  These cigarette-specific taxes \((CigTax_i)\) constitute a possible
  second instrumental variable.
\item
  The cigarette-specific tax increases the price of cigarettes paid by
  the consumer, so it arguably meets the condition for instrument
  relevance. If it is uncorrelated with the error term in the state
  cigarette demand equation, it is an exogenous instrument.
\item
  With this additional instrument in hand, we now have two instrumental
  variables, the real sales tax per pack and the real state
  cigarette-specific tax per pack. With two instruments and a single
  endogenous regressor, the demand elasticity is overidentified; that
  is, the number of instruments (\(SalesTax_i\) and \(CigTax_i\), so
  \(m = 2\)) exceeds the number of included endogenous variables
  (\(P^{cigarettes}_i\) , so \(k = 1\)).
\end{itemize}

We can estimate the demand elasticity using TSLS, where the regressors
in the first-stage regression are the included exogenous variable,
\(\ln(Inc_i)\), and both instruments.

\begin{itemize}
\item
  The resulting TSLS estimate of the regression function using the two
  instruments \(SalesTax_i\) and \(CigTax_i\) is
\end{itemize}

\[\widehat{\ln(Q^{cigarettes}_i)}  = \underset{(0.96)}{9.89} - \underset{(0.25)}{1.28} \ln(P^{cigarettes}_i) + \underset{(0.25)}{0.28} \ln(Inc_i). (12.16)\]

\begin{itemize}
\item
  Compare Equations (12.15) and (12.16): The standard error of the
  estimated price elasticity is smaller by one-third in Equation (12.16)
  {[}0.25 in Equation (12.16) versus 0.37 in Equation (12.15){]}.
\item
  The reason the standard error is smaller in Equation (12.16) is that
  this estimate uses more information than Equation (12.15): In
  Equation(12.15), only one instrument (the sales tax) is used, but in
  Equation (12.16), two instruments (the sales tax and the
  cigarette-specific tax) are used. Using two instruments explains more
  of the variation in cigarette prices than using just one, and this is
  reflected in smaller standard errors on the estimated demand
  elasticity.
\item
  Are these estimates credible? Ultimately, credibility depends on
  whether the set of instrumental variables---here, the two
  taxes---plausibly satisfies the two conditions for valid instruments.
  It is therefore vital that we assess whether these instruments are
  valid, and it is to this topic that we now turn.
\end{itemize}
\end{frame}

\section{Checking Instrument Validity}
\begin{frame}{Checking Instrument Validity}
\begin{itemize}
\item
  Whether instrumental variables regression is useful in a given
  application hinges on whether the instruments are valid: Invalid
  instruments produce meaningless results.
\item
  It therefore is essential to assess whether a given set of instruments
  is valid in a particular application.
\end{itemize}
\end{frame}

\begin{frame}[allowframebreaks]{Assumption 1: Instrument Relevance}

The role of the instrument relevance condition in IV regression is
subtle. One way to think of instrument relevance is that it plays a role
akin to the sample size: The more relevant are the instruments---that
is, the more the variation in \(X\) is explained by the
instruments---the \textbf{more information} is available for use in IV
regression.

\begin{itemize}
\item
  A more relevant instrument produces a more accurate estimator, just as
  a larger sample size produces a more accurate estimator.
\item
  Moreover, statistical inference using TSLS is predicated on the TSLS
  estimator having a normal sampling distribution, but according to the
  central limit theorem, the normal distribution is a good approximation
  in large---but not necessarily small---samples.
\item
  If having a more relevant instrument is like having a larger sample
  size, this suggests, correctly, that the more relevant is the
  instrument, the better is the normal approximation to the sampling
  distribution of the TSLS estimator and its t-statistic.
\item
  Instruments that explain little of the variation in X are called
  \textbf{\emph{weak instruments}}. In the cigarette example, the
  distance of the state from cigarette manufacturing plants arguably
  would be a weak instrument:
\item
  Although a greater distance increases shipping costs (thus shifting
  the supply curve in and raising the equilibrium price), cigarettes are
  lightweight, so shipping costs are a small component of the price of
  cigarettes. Thus the amount of price variation explained by shipping
  costs, and thus distance to manufacturing plants, probably is quite
  small.
\end{itemize}
\end{frame}

\begin{frame}[allowframebreaks]{Why weak instruments are a problem}
\begin{itemize}
\item
  If the instruments are weak, then the normal distribution provides a
  poor approximation to the sampling distribution of the TSLS estimator,
  even if the sample size is large.

  \begin{itemize}
  \item
    Thus there is no theoretical justification for the usual methods for
    performing statistical inference, even in large samples.
  \end{itemize}
\item
  In fact, if instruments are weak, then the TSLS estimator \textbf{can
  be badly biased i}n the direction of the OLS estimator. In addition,
  95\% confidence intervals constructed as the TSLS estimator \{1.96
  standard errors can contain the true value of the coefficient far less
  than 95\% of the time. In short, if instruments are weak, TSLS is no
  longer reliable.
\item
  To see that there is a problem with the large-sample normal
  approximation to the sampling distribution of the TSLS estimator,
  consider the special case of a single included endogenous variable, a
  single instrument, and no included exogenous regressor.
\item
  If the instrument is valid, then \(\hat \beta_1^{TSLS}\) is consistent
  because the sample covariances \(s_{ZY}\) and \(s_{ZX}\) are
  consistent; that
  is,\(\hat \beta_1^{TSLS} = \frac{s_{ZY}}{s_{ZX}} \to_p cov(Z,Y)/cov(Z,X) = \beta_1\)
  {[}Equation (12.7){]}.
\item
  But now suppose that the instrument is not just weak but in fact is
  irrelevant, so that \(cov(Z_i, X_i) = 0\). Then
  \(s_{ZX} \to cov(Z,X)= 0\), so, taken literally, the denominator on
  the right-hand side of the limit \(cov(Z_i,Y_i)/cov(Z_i,X_i)\) is 0.
\item
  The argument that \(\hat \beta^{TSLS}\) is consistent breaks down when
  the instrument relevance condition fails.
\item
  This breakdown results in the TSLS estimator having \textbf{a
  nonnormal sampling distribution,} even if the sample size is very
  large.
\item
  In fact, when the instrument is irrelevant, the large-sample
  distribution of \(\hat \beta^{TSLS}\) is not the distribution of a
  normal random variable but rather the distribution of a ratio of two
  normal random variables! As discussed in Appendix 12.4, thisr
  atio-of-normals distribution is centered at the large-sample value of
  the OLS estimator.
\item
  While this circumstance of totally irrelevant instruments might not be
  encountered in practice, it raises a question: How relevant must the
  instruments be for the normal distribution to provide a good
  approximation in practice? The answer to this question in the general
  IV model is complicated. Fortunately, however, there is a simple rule
  of thumb available for the most common situation in practice, the case
  of a single endogenous regressor.
\end{itemize}
\end{frame}

\begin{frame}[allowframebreaks]{Checking for weak instruments when there is a single endogenous regressor}

\begin{itemize}
\item
  One way to check for weak instruments when there is a single
  endogenous regressor is to compute the F-statistic testing the
  hypothesis that the coefficients on the instruments are all 0 in the
  first-stage regression of TSLS.
\item
  This first-stage F-statistic provides a measure of the information
  content contained in the instruments: The more information content,
  the larger the expected value of the F-statistic.
\item
  One simple rule of thumb is that you do not need to worry about weak
  instruments if the first-stage F-statistic \textbf{exceeds 10}. (Why
  10? See Appendix 12.5.)
\end{itemize}
\end{frame}

\begin{frame}[allowframebreaks]{What do I do if I have weak instruments?}
\begin{itemize}
\item
  If you have many instruments, some of those instruments are probably
  weaker than others. If you have a small number of strong instruments
  and many weak ones, you will be better off discarding the weakest
  instruments and using the most relevant subset for your TSLS analysis.
  Your TSLS standard errors might increase when you drop weak
  instruments, but keep in mind that your original standard errors were
  not meaningful anyway!
\item
  If, however, the coefficients are exactly identified, you cannot
  discard the weak instruments. Even if the coefficients are
  overidentified, you might not have enough strong instruments to
  achieve identification, so discarding some weak instruments will not
  help. In this case, you have two options. The first option is to find
  additional, stronger instruments. This is easier said than done: It
  requires an intimate knowledge of the problem at hand and can entail
  redesigning the data set and the nature of the empirical study.
\item
  The second option is to proceed with your empirical analysis using the
  weak instruments, but employing methods other than TSLS. Although this
  chapter has focused on TSLS, some other methods for instrumental
  variable analysis are less sensitive to weak instruments than TSLS,
  and some of these methods are discussed in Appendix 12.5.
\end{itemize}

\end{frame}

\begin{frame}[allowframebreaks]{Assumption 2: Instrument Exogeneity}

\begin{itemize}
\item
  If the instruments are not exogenous, then TSLS is inconsistent: The
  TSLS estimator converges in probability to something other than the
  causal coefficient. After all, the idea of instrumental variables
  regression is that the instrument contains information about variation
  in Xi that is unrelated to the error term \(u_i\).
\item
  If, in fact, the instrument is not exogenous, it cannot pinpoint this
  exogenous variation in \(X_i\), and it stands to reason that IV
  regression fails to provide a consistent estimator.
\end{itemize}

\end{frame}

\begin{frame}[allowframebreaks]{Can you statistically test the assumption
that the instruments are exogenous?}

\begin{itemize}
\item
  Yes and no. On the one hand, it is not possible to test the hypothesis
  that the instruments are exogenous when the coefficients are exactly
  identified. On the other hand, if the coefficients are overidentified,
  it is possible to test the overidentifying restrictions---that is, to
  test the hypothesis that the ``extra'' instruments are exogenous under
  the maintained assumption that there are enough valid instruments to
  identify the coefficients of interest.
\item
  First consider the case that the coefficients are exactly identified,
  so you have as many instruments as endogenous regressors. Then it is
  impossible to develop a statistical test of the hypothesis that the
  instruments are, in fact, exogenous. That is, empirical evidence
  cannot be brought to bear on the question of whether these instruments
  satisfy the exogeneity restriction. In this case, the only way to
  assess whether the instruments are exogenous is to draw on expert
  opinion and your personal knowledge of the empirical problem at hand.
  For example, Philip Wright's knowledge of agricultural supply and
  demand led him to suggest that below-average rainfall would plausibly
  shift the supply curve for fats and oils but would not directly shift
  the demand curve.
\item
  Assessing whether the instruments are exogenous necessarily requires
  making an expert judgment based on personal knowledge of the
  application. If, however, there are more instruments than endogenous
  regressors, then there is a statistical tool that can be helpful in
  this process: the so-called test of overidentifying\\
  restrictions.
\end{itemize}
\end{frame}

\begin{frame}[allowframebreaks]{The overidentifying restrictions test}

\begin{itemize}
\item
  Suppose you have a single endogenous regressor and two instruments.
  Then you could compute two different TSLS estimators: one using the
  first instrument and the other using the second. These two estimators
  will not be the same because of sampling variation, but if both
  instruments are exogenous, then they will tend to be close to each
  other. But what if these two instruments produce very different
  estimates? You might sensibly conclude that there is something wrong
  with one or the other of the instruments or with both. That is, it
  would be reasonable to conclude that one or the other or both of the
  instruments are not exogenous.
\item
  The test of overidentifying restrictions implicitly makes this
  comparison. We say implicitly because the test is carried out without
  actually computing all of the different possible IV estimates. Here is
  the idea. Exogeneity of the instruments means that they are
  uncorrelated with \(u_i\).\\
  This suggests that the instruments should be approximately
  uncorrelated with \(\hat u^{TSLS}_i\), where
  \(\hat u^{TSLS}_i = Y_i - (\hat \beta_0^{TSLS} + \hat \beta_1^{TSLS}X_{1i} + \ldots +  \hat \beta_{k+r}^{TSLS}W_{ri})\)
  \\
  is the residual from the estimated TSLS regression using all the
  instruments (approximately rather than exactly because of sampling
  variation). (Note that these residuals are constructed using the true
  \(X\)'s rather than their first-stage predicted values.)
\item
  Accordingly, if the instruments are, in fact, exogenous, then the
  coefficients on the instruments in a regression of unTSLS \(i\) on the
  instruments and the included exogenous variables should all be \(0\),
  and this hypothesis can be tested.
\item
  This method for computing the overidentifying restrictions test is
  summarized in Key Concept 12.6. This statistic is computed using the
  homoskedasticity-only F-statistic. The test statistic is commonly
  called the J-statistic and is computed as \(J = mF\).
\item
  In large samples, if the instruments are not weak and the errors are
  homoskedastic, then, under the null hypothesis that the instruments
  are exogenous, the J-statistic has a chi-squared distribution with
  \(m- k\) degrees of freedom \((\chi^2_{m-k})\).
\item
  It is important to remember that even though the number of
  restrictions being tested is \(m\), the degrees of freedom of the
  asymptotic distribution of the J-statistic is \(m - k\). The\\
  reason is that it is possible to test only the overidentifying
  restrictions, of which there are \(m - k\).
\item
  The easiest way to see that you cannot test the exogeneity of the
  regressors when the coefficients are exactly identified \((m = k)\) is
  to consider the case of a single included endogenous variable
  \((k = 1)\). \\
  If there are two instruments, then you can compute two TSLS
  estimators, one for each instrument, and you can compare them to see
  if they are close. But if you have only one instrument, then you can
  compute only one TSLS estimator, and you have nothing to which to
  compare it.
\item
  In fact, if the coefficients are exactly identified, so that
  \(m = k\), then the overidentifying test statistic \(J\) is exactly 0.
\end{itemize}
\end{frame}

\section[Application]{Application to the Demand for Cigarettes}
\begin{frame}[allowframebreaks]{Application to the Demand for Cigarettes}
  
\begin{itemize}
\item
  Our attempt to estimate the elasticity of demand for cigarettes left
  off with the TSLS estimates summarized in Equation (12.16), in which
  income was an included exogenous variable and there were two
  instruments, the general sales tax and the cigarettespecific\\
  tax.
\item
  We can now undertake a more thorough evaluation of these instruments.
\item
  As in Section 12.1, it makes sense that the two instruments are
  relevant because taxes are a big part of the after-tax price of
  cigarettes, and shortly we will look at this empirically. First,
  however, we focus on the difficult question of whether the two tax
  variables are plausibly exogenous.
\item
  The first step in assessing whether an instrument is exogenous is to
  think through the arguments for why it may or may not be. This
  requires thinking about which factors account for the error term in
  the cigarette demand equation and whether these factors are plausibly
  related to the instruments.
\item
  Why do some states have higher per capita cigarette consumption than
  others?

  \begin{itemize}
  \item
    One reason might be variation in incomes across states, but state
    income is included in Equation (12.16), so this is not part of the
    error term. Another reason is that there are historical factors
    influencing demand. For example, states that grow tobacco have
    higher rates of smoking than most other states. Could this factor be
    related to taxes?
  \item
    Quite possibly: If tobacco farming and cigarette production are
    important industries in a state, then these industries could exert
    influence to keep cigarette-specific taxes low. This suggests that
    an omitted factor in cigarette demand---whether the state grows
    tobacco and produces cigarettes---could be correlated with
    cigarette-specific taxes.
  \end{itemize}
\item
  One solution to this possible correlation between the error term and
  the instrument would be to include information on the size of the
  tobacco and cigarette industry in the state;

  \begin{itemize}
  \item
    this is the approach we took when we included income as a regressor
    in the demand equation. But because we have panel data on cigarette
    consumption, a different approach is available that does not require
    this information.
  \item
    As discussed in Chapter 10, panel data make it possible to eliminate
    the influence of variables that vary across entities (states) but do
    not change over time, such as the historical circumstances that lead
    to a large tobacco and cigarette industry in a state.
  \item
    Two methods for doing this were given in Chapter 10: constructing
    data on changes in the variables between two different time periods
    and using fixed effects regression. To keep the analysis here as
    simple as possible, we adopt the former approach and perform
    regressions of the type described in Section 10.2, based on the
    changes in the variables between two different years.
  \end{itemize}
\item
  The time span between the two different years influences how the
  estimated elasticities are to be interpreted. Because cigarettes are
  addictive, changes in price will take some time to alter behavior. At
  first, an increase in the price of cigarettes might have little effect
  on demand.
\item
  Over time, however, the price increase might contribute to some
  smokers' desire to quit, and, importantly, it could discourage
  nonsmokers from taking up the habit. Thus the response of demand to a
  price increase could be small in the short run but large in the long
  run.
\item
  Said differently, for an addictive product like cigarettes, demand
  might be inelastic in the short run---that is, it might have a
  short-run elasticity near 0---but it might be more elastic in the long
  run.
\end{itemize}

In this analysis, we focus on estimating the long-run price elasticity.
We do this by considering quantity and price changes that occur over
10-year periods. Specifically, in the regressions considered here, the
10-year change in log quantity,
\(\ln(Q^{cigarettes}_{i,1995}) - \ln(Q^{cigarettes}_{i,1985})\), is
regressed against the 10-year change in log price,
\(\ln(P^{cigarettes}_{i,1995}) - \ln(P^{cigarettes}_{i,1985})\), and the
10-year change in log income, \(\ln(Inc_{i,1995}) - \ln(Inc_{i,1985})\).

\begin{itemize}
\item
  Two instruments are used: the change in the sales tax over 10 years,
  \(SalesTax_{i,1995} - SalesTax_{i,1985}\), and the change in the
  cigarette-specific tax over 10 years,
  \(CigTax_{i,1995} - CigTax_{i,1985}\).
\end{itemize}
\end{frame}

\begin{frame}
  
\begin{figure}
\centering
\includegraphics[width=\linewidth]{../figure/W5_1.png}
\end{figure}
\end{frame}

\begin{frame}[allowframebreaks]{Results}


\begin{itemize}
\item
  The results are presented in Table 12.1. As usual, each column in the
  table presents the results of a different regression. All regressions
  have the same regressors, and all coefficients are estimated using
  TSLS; the only difference among the three regressions is the set of
  instruments used. In column (1), the only instrument is the sales tax;
  in column (2), the only instrument is the cigarette-specific tax; and
  in column (3), both taxes are used as instruments.
\end{itemize}

In IV regression, the reliability of the coefficient estimates hinges on
the validity of the instruments, so the first things to look at in Table
12.1 are the diagnostic statistics assessing the validity of the
instruments.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  First, are the instruments relevant? We need to look at the
  first-stage F-statistics. The first-stage regression in column (1) is
\end{enumerate}

\begin{align*}
\ln(P^{cigarettes}_{i,1995}) - \ln(P^{cigarettes}_{i,1985}) = \underset{(0.03)}{0.53} - \underset{(0.22)}{0.223} (\ln(Inc_{i,1995}) - \ln(Inc_{i,1985}) ) \\ + \underset{(0.0044)}{0.0255} (SalesTax_{i,1995} - SalesTax_{i,1985} ).
\end{align*}

Because there is only one instrument in this regression, the first-stage
F-statistic is the square of the t-statistic testing that the
coefficient on the instrumental variable,
\(SalesTax_{i,1995} - SalesTax_{i,1985}\), is 0; this is
\(F = t^2 = (0.0255 / 0.00442 ) = 33.7\).

For the regressions in columns (2) and (3), the first-stage F-statistics
are \(107.2\) and \(88.6\), so in all three cases the first-stage
F-statistics exceed 10. We conclude that the instruments are not weak,
so we can rely on the standard methods for statistical inference
(hypothesis tests and confidence intervals) using the TSLS coefficients
and standard errors.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Second, are the instruments exogenous? Because the regressions in
  columns (1) and (2) each have a single instrument and a single
  included endogenous regressor, the coefficients in those regressions
  are exactly identified. Thus we cannot deploy the J-test in either of
  those regressions. The regression in column (3), however, is
  overidentified because there are two instruments and a single included
  endogenous regressor, so there is one \((m - k = 2 - 1 = 1)\)
  overidentifying restriction. The J-statistic is 4.93; this has a
  \(\chi^2_1\) distribution, so the 5\% critical value is 3.84 (Appendix
  Table 3 ) and the null hypothesis that both the instruments are
  exogenous is rejected at the 5\% significance level (this deduction
  also can be made directly from the p-value of 0.026, reported in the
  table).
\end{enumerate}

\begin{itemize}
\item
  The reason the \(J\)-statistic rejects the null hypothesis that both
  instruments are exogenous is that the two instruments produce rather
  different estimated coefficients.
\item
  When the only instrument is the sales tax {[}column (1){]}, the
  estimated price elasticity is -0.94, but when the only instrument is
  the cigarette-specific tax, the estimated price elasticity is -1.34.
  Recall the basic idea of the J-statistic: If both instruments are
  exogenous, then the two TSLS estimators using the individual
  instruments are consistent and differ from each other only because of
  random sampling variation. If, however, one of the instruments is
  exogenous and one is not, then the estimator based on the endogenous
  instrument is inconsistent, which is detected by the J-statistic. In
  this application, the difference between the two estimated price
  elasticities is sufficiently large that it is unlikely to be the
  result of pure sampling variation, so the J-statistic rejects the null
  hypothesis that both the instruments are exogenous.
\item
  The J-statistic rejection means that the regression in column (3) is
  based on invalid instruments (the instrument exogeneity condition
  fails). What does this imply about the estimates in columns (1) and
  (2)? The J-statistic rejection says that at least one of the
  instruments is endogenous, so there are three logical possibilities:
  The sales tax is exogenous but the cigarette-specific tax is not, in
  which case the column (1) regression is reliable; the
  cigarette-specific tax is exogenous but the sales tax is not, so the
  column (2) regression is reliable; or neither tax is exogenous, so
  neither regression is reliable. The statistical evidence cannot tell
  us which possibility is correct, so we must use our judgment.
\item
  We think that the case for the exogeneity of the general sales tax is
  stronger than that for the cigarette-specific tax because the
  political process can link changes in the cigarette-specific tax to
  changes in the cigarette market and smoking policy. For example, if
  smoking decreases in a state because it falls out of fashion, there
  will be fewer smokers and a weakened lobby against cigarette-specific
  tax increases, which in turn could lead to higher cigarette-specific
  taxes. Thus changes in tastes (which are part of u) could be
  correlated with changes in cigarette-specific taxes (the instrument).
  This suggests discounting the IV estimates that use the cigarette-only
  tax as an instrument and adopting the price elasticity estimated using
  the general sales tax as an instrument, -0.94.
\item
  The estimate of -0.94 indicates that cigarette consumption is somewhat
  elastic: An increase in price of 1\% leads to a decrease in
  consumption of 0.94\%. This may seem surprising for an addictive
  product like cigarettes. But remember that this elasticity is computed
  using changes over a 10-year period, so it is a long-run elasticity.
  This estimate suggests that increased taxes can make a substantial
  dent in cigarette consumption, at least in the long run. When the
  elasticity is estimated using 5-year changes from 1985 to 1990 rather
  than the 10-year changes reported in Table 12.1, the elasticity
  (estimated with the general sales tax as the instrument) is -0.79; for
  changes from 1990 to 1995, the elasticity is -0.68. These estimates
  suggest that demand is less elastic over horizons of 5 years than over
  10 years. This finding of greater price elasticity at longer horizons
  is consistent with the large body of research on cigarette demand.
  Demand elasticity estimates in that literature typically fall in the
  range -0.3 to -0.5, but these are mainly short-run elasticities; some
  studies suggest that the long-run elasticity could be perhaps twice
  the short-run elasticity.
\end{itemize}
\end{frame}

\begin{frame}[allowframebreaks]{Where Do Valid Instruments Come From?}
  
\begin{itemize}
\item
  In practice, the most difficult aspect of IV estimation is finding
  instruments that are both relevant and exogenous. There are two main
  approaches, which reflect two different perspectives on econometric
  and statistical modeling.
\item
  The first approach is to use economic theory to suggest instruments.
  For example, Philip Wright's understanding of the economics of
  agricultural markets led him to look for an instrument that shifted
  the supply curve but not the demand curve; this in turn led him to
  consider weather conditions in agricultural regions. One area where
  this approach has been particularly successful is the field of
  financial economics.\\
  Some economic models of investor behavior involve statements about how
  investors forecast, which then imply sets of variables that are
  uncorrelated with the error term. Those models sometimes are nonlinear
  in the data and in the parameters, in which case the IV estimators
  discussed in this chapter cannot be used. An extension of IV methods
  to nonlinear models, called generalized method of moments estimation,
  is used instead. Economic theories are, however, abstractions that
  often do not take into account the nuances and details necessary for
  analyzing a particular data set. Thus this approach does not always
  work.
\item
  The second approach to constructing instruments is to look for some
  exogenous source of variation in \(X\) arising from what is, in
  effect, a random phenomenon that induces shifts in the endogenous
  regressor. For example, in our hypothetical example in Section 12.1,
  earthquake damage increased average class size in some school
  districts, and this variation in class size was unrelated to potential
  omitted variables that affect student achievement. This approach
  typically requires knowledge of the problem being studied and careful
  attention to the details of the data, and it is best explained through
  examples.
\end{itemize}

\end{frame}


\begin{frame}[allowframebreaks]{Do economic institutions affect economic development?}

  \begin{itemize}
\item
  The single question that has troubled economists since Adam Smith the
  most is why some nations are rich while others remain poor. Unpicking
  the various mechanisms that lead to economic growth and evaluating the
  contribution of each mechanism requires a combination of theory and
  empirical analysis. However, such empirical analysis is not as
  straightforward as it seems. For example, the role played by
  institutions, such as legal institutions that facilitate the ownership
  of property. It is quite plausible that strong institutions that
  foster property rights could lead to higher economic growth if they
  incentivized a more efficient use of scarce resources.
\item
  Disentangling this particular issue is challenging, precisely because
  economic institutions and economic growth are so interconnected. This
  means that a simple regression of some measure of economic development
  (GDP per capita) against a measure of institutions, such as protection
  against expropriation (the strength of the property rights in a
  country), will yield a biased estimate of the causal effect of
  institutions on economic development even if the analyst controls for
  a number of other factors affecting economic development, such as
  whether a country is landlocked or not. This results from the serious
  potential for simultaneous causality bias in this analysis: Stronger
  institutions can lead to greater economic development. Conversely,
  however, economic growth could enable the creation of these kinds of
  institutions and institutional arrangements. As a result there is a
  ``chicken and egg'' situation where it is not clear which comes first.
  As in the butter example in Figure 12.1, because of this simultaneous
  causality, an OLS regression of economic development on a measure of
  institutions will estimate some complicated combination of these two
  effects. This problem cannot be solved by finding better control
  variables.
\item
  This simultaneous causality bias, however, can be eliminated by
  finding a suitable instrumental variable and using TSLS. The
  instrument must be correlated with the measure of institutions (it
  must be relevant), but it must also be uncorrelated with the error
  term in the economic development equation of interest (it must be
  exogenous). That is it must affect the measure of institutions but be
  unrelated to any of the unobserved factors that determine economic
  development.
\item
  Things that might affect the ability to have strong economic
  institutions are very likely to be related to the economic performance
  of a country. So where does one find something that affects
  institutions but has no direct effect on economic development? Because
  it takes a long time for institutions to become established, one idea
  is to consider the history of how economic institutions were first
  developed. Plausibly there may be factors from hundreds of years ago
  that were relevant in the initial founding of institutions, but are
  not related to the level of economic development today except for
  through their impact on institutions. Specifically, Acemoglu et al.
  (2001) consider the colonial origins of economic institutions. They
  argue that the potential mortality rate among settlers was influential
  in determining whether European countries established ``Neo-Europes''
  involving setting up European-style institutions that protected
  private property rights or instead set up ``extractive states.'' They
  further argue that these differences in institutions persist to the
  present day.
\item
  Are measures of potential settler mortality valid instruments?
  Although Acemoglu et al. did not report first-stage F-statistics,
  settler mortality alone was found to explain 27\% of the levels of
  current institutions, suggesting that this instrument is relevant.3
  The argument that the instruments are exogenous requires that settler
  mortality only affects economic development through the effect on
  institutions. As a robustness check, to investigate whether settler
  mortality may have been caused by diseases that still exist and that
  may hamper economic performance today, Acemoglu et al. include
  prevalence of malaria in their regression. They find that the
  inclusion of this regressor makes little difference to the resulting
  regression coefficients. In addition, because Acemoglu et al. break
  down the causal pathway through which settler mortality affects
  current institutions into three parts, there are three instruments
  and, therefore, overidentifying restrictions can be tested. The
  failure to reject the null hypotheses of these tests bolsters the case
  that the instruments are valid.
\item
  Using these instruments and TSLS, Acemoglu et al. estimated the effect
  on economic development of institutions to be substantial. This
  estimated effect was twice as large as the effect estimated using OLS,
  suggesting that OLS suffered from large simultaneous causality bias.
  In addition, they find that in the TSLS model neither the coefficient
  on the dummy for Africa nor a country's distance from the equator are
  statistically significant suggesting that ``Africa is poorer than the
  rest of the world not because of pure geographic or cultural factors,
  but because of worse institutions.
\end{itemize}
\end{frame}

\begin{frame}[allowframebreaks]{Does cutting class sizes increase test scores?}
\begin{itemize}
\item
  As we saw in the empirical analysis of Part II, schools with small
  classes tend to be wealthier, and their students have access to
  enhanced learning opportunities both in and out of the classroom. In
  Part II, we used multiple regression to tackle the threat of omitted
  variables bias by controlling for various measures of student
  affluence, ability to speak English, and so forth. Still, a skeptic
  could wonder whether we did enough: If we left out something
  important, our estimates of the class size effect would still be
  biased.
\item
  This potential omitted variables bias could be addressed by including
  the right control variables, but if these data are unavailable (some,
  like outside learning opportunities, are hard to measure), then an
  alternative approach is to use IV regression. This regression requires
  an instrumental variable correlated with class size (relevance) but
  uncorrelated with the omitted determinants of test performance that
  make up the error term, such as parental interest in learning,
  learning opportunities outside the classroom, quality of the teachers
  and school facilities, and so forth (exogeneity).
\item
  Where does one look for an instrument that induces random, exogenous
  variation in class size, but is unrelated to the other determinants of
  test performance? Hoxby (2000) suggested biology. Because of random
  fluctuations in timings of births, the size of the incoming
  kindergarten class varies from one year to the next. Although the
  actual number of children entering kindergarten might be endogenous
  (recent news about the school might influence whether parents send a
  child to a private school), she argued that the potential number of
  children entering kindergarten---the number of 4-year-olds in the
  district---is mainly a matter of random fluctuations in the birth
  dates of children.
\item
  Is potential enrollment a valid instrument? Whether it is exogenous
  depends on whether it is correlated with unobserved determinants of
  test performance. Surely biological fluctuations in potential
  enrollment are exogenous, but potential enrollment also fluctuates
  because parents with young children choose to move into an improving
  school district and out of one in trouble. If so, an increase in
  potential enrollment could be correlated with unobserved factors such
  as the quality of school management, rendering this instrument
  invalid. Hoxby addressed this problem by reasoning that growth or
  decline in the potential student pool for this reason would occur
  smoothly over several years, whereas random fluctuations in birth
  dates would produce short-term ``spikes'' in potential enrollment.
  Thus she used as her instrument not potential enrollment, but the
  deviation of potential enrollment from its longterm trend. These
  deviations satisfy the criterion for instrument relevance (the
  firststage F-statistics all exceed 100). She makes a good case that
  this instrument is exogenous, but, as in all IV analysis, the
  credibility of this assumption is ultimately a matter of judgment.
\item
  Hoxby implemented this strategy using detailed panel data on
  elementary schools in Connecticut in the 1980s and 1990s. The panel
  data set permitted her to include school fixed effects, which, in
  addition to the instrumental variables strategy, attack the problem of
  omitted variables bias at the school level. Her TSLS estimates
  suggested that the effect on test scores of class size is small; most
  of her estimates were statistically insignificantly different from 0.
\end{itemize}
\end{frame}

\begin{frame}[allowframebreaks]{Does aggressive treatment of heart attacks prolong lives?}
\begin{itemize}
\item
  Aggressive treatments for victims of heart attacks (technically, acute
  myocardial infarctions, or AMIs) hold the potential for saving lives.
  Before a new medical procedure---in this example, cardiac
  catheterization5---is approved for general use, it goes through
  clinical trials, a series of randomized controlled experiments
  designed to measure its effects and side effects. But strong
  performance in a clinical trial is one thing; actual performance in
  the real world is another.
\item
  A natural starting point for estimating the real-world effect of
  cardiac catheterization is to compare patients who received the
  treatment to those who did not. This leads to regressing the length of
  survival of the patient against the binary treatment variable (whether
  the patient received cardiac catheterization) and other control
  variables that affect mortality (age, weight, other measured health
  conditions, and so forth). The population coefficient on the indicator
  variable is the increment to the patient's life expectancy provided by
  the treatment. Unfortunately, the OLS estimator is subject to bias:
  Cardiac catheterization does not ``just happen'' to a patient
  randomly; rather, it is performed because the doctor and patient
  decide that it might be effective. If their decision is based in part
  on unobserved factors relevant to health outcomes not in the data set,
  the treatment decision will be correlated with the regression error
  term. If the healthiest patients are the ones who receive the
  treatment, the OLS estimator will be biased (treatment is correlated
  with an omitted variable), and the treatment will appear more
  effective than it really is.
\item
  This potential bias can be eliminated by IV regression using a valid
  instrumental variable. The instrument must be correlated with
  treatment (must be relevant) but must be uncorrelated with the omitted
  health factors that affect survival (must be exogenous).
\item
  Where does one look for something that affects treatment but does not
  affect the health outcome other than through its effect on treatment?
  McClellan, McNeil, and Newhouse (1994) suggested geography. Most
  hospitals in their data set did not offer cardiac catheterization, so
  many patients were closer to ``regular'' hospitals that did not offer
  this treatment than to cardiac catheterization hospitals. McClellan,
  McNeil, and Newhouse therefore used as an instrumental variable the
  difference between the distance from the AMI patient's home to the
  nearest cardiac catheterization hospital and the distance to the
  nearest hospital of any sort; this distance is 0 if the nearest
  hospital is a cardiac catheterization hospital, and otherwise it is
  positive. If this relative distance affects the probability of
  receiving this treatment, then it is relevant. If it is distributed
  randomly across AMI victims, then it is exogenous.
\item
  Is relative distance to the nearest cardiac catheterization hospital a
  valid instrument? McClellan, McNeil, and Newhouse do not report
  first-stage F-statistics, but they do provide other empirical evidence
  that it is not weak. Is this distance measure exogenous? They make two
  arguments. First, they draw on their medical expertise and knowledge
  of the health care system to argue that distance to a hospital is
  plausibly uncorrelated with any of the unobservable variables that
  determine AMI outcomes. Second, they have data on some of the
  additional variables that affect AMI outcomes, such as the weight of
  the patient, and in their sample, distance is uncorrelated with these
  observable determinants of survival; this, they argue, makes it more
  credible that distance is uncorrelated with the unobservable
  determinants in the error term as well.
\item
  Using 205,021 observations on Americans aged at least 64 who had an
  AMI in 1987, McClellan, McNeil, and Newhouse reached a striking
  conclusion: Their TSLS estimates suggest that cardiac catheterization
  has a small, possibly 0, effect on health outcomes; that is, cardiac
  catheterization does not substantially prolong life. In contrast, the
  OLS estimates suggest a large positive effect. They interpret this
  difference as evidence of bias in the OLS estimates.
\item
  McClellan, McNeil, and Newhouse's IV method has an interesting
  interpretation. The OLS analysis used actual treatment as the
  regressor, but because actual treatment is itself the outcome of a
  decision by patient and doctor, they argue that the actual treatment
  is correlated with the error term. Instead, TSLS uses predicted
  treatment, where the variation in predicted treatment arises because
  of variation in the instrumental variable: Patients closer to a
  cardiac catheterization hospital are more likely to receive this
  treatment.
\item
  This interpretation has two implications. 
  \begin{enumerate}
    \item the IV regression actually estimates the effect of the treatment not on a ``typical'' randomly selected patient but rather on patients for whom distance is an important consideration in the treatment decision. The effect on those patients might differ from the effect on a typical patient, which provides one explanation of the greater estimated effectiveness of the treatment in clinical trials than in McClellan, McNeil, and  Newhouse's IV study.
    \item it suggests a general strategy for finding instruments in this type of setting: Find an instrument that affects the probability of treatment, but does so for reasons that are unrelated to the outcome except through their effect on the likelihood of treatment. Both these implications have applicability to experimental and ``quasi-experimental'' studies.
  \end{enumerate}
\end{itemize}
\end{frame}

\begin{frame}[allowframebreaks,noframenumbering]
	\frametitle{References}
	\bibliographystyle{apalike}
	\bibliography{library}
\end{frame}

\end{document}
